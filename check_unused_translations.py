#!/usr/bin/env python3
"""
Barké¡¹ç›®æœ¬åœ°åŒ–å­—ç¬¦ä¸²åˆ†æå·¥å…·

è¿™ä¸ªè„šæœ¬ä¼šæ‰«ææ•´ä¸ªBarké¡¹ç›®ï¼Œæ‰¾å‡º Localizable.xcstrings ä¸­æœªä½¿ç”¨çš„ç¿»è¯‘keyã€‚
æ£€æµ‹æ–¹å¼ï¼šä»»ä½•åœ¨åŒå¼•å·å†…ä¸”åœ¨æœ¬åœ°åŒ–æ–‡ä»¶ä¸­å®šä¹‰çš„å­—ç¬¦ä¸²éƒ½ä¼šè¢«è®¤ä¸ºæ˜¯è¢«ä½¿ç”¨çš„keyã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 check_unused_translations.py
    
è¾“å‡º:
    - æ§åˆ¶å°æ˜¾ç¤ºåˆ†æç»“æœ
"""

import json
import os
import re
import sys
from pathlib import Path

class BarkLocalizationAnalyzer:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.localization_file = self.project_root / "Bark" / "Localizable.xcstrings"
        
    def extract_all_keys(self):
        """æå– Localizable.xcstrings ä¸­çš„æ‰€æœ‰key"""
        try:
            with open(self.localization_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return set(data['strings'].keys())
        except Exception as e:
            print(f"âŒ è¯»å–æœ¬åœ°åŒ–æ–‡ä»¶å¤±è´¥: {e}")
            return set()
    
    def find_swift_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰Swiftæºç æ–‡ä»¶"""
        swift_files = []
        for path in self.project_root.rglob("*.swift"):
            # è·³è¿‡Podså’Œbuildç›®å½•
            if "Pods" not in str(path) and "build" not in str(path):
                swift_files.append(path)
        return swift_files
    
    def extract_used_keys_from_file(self, file_path, all_defined_keys):
        """ä»Swiftæ–‡ä»¶ä¸­æå–ä½¿ç”¨çš„æœ¬åœ°åŒ–key"""
        used_keys = set()
        nslocalizedstring_keys = set()  # æ–°å¢ï¼šä¸“é—¨æ”¶é›†NSLocalizedStringä¸­çš„key
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ–¹æ³•1: æŸ¥æ‰¾æ‰€æœ‰åœ¨åŒå¼•å·å†…çš„å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬å¤šè¡Œå’Œè½¬ä¹‰å­—ç¬¦
            quoted_strings = re.findall(r'"([^"]*)"', content, re.MULTILINE | re.DOTALL)
            
            # æ£€æŸ¥å“ªäº›å¼•å·å†…çš„å­—ç¬¦ä¸²æ˜¯å·²å®šä¹‰çš„æœ¬åœ°åŒ–key
            for quoted_string in quoted_strings:
                # å»æ‰å‰åç©ºç™½å­—ç¬¦
                quoted_string = quoted_string.strip()
                if quoted_string and quoted_string in all_defined_keys:
                    used_keys.add(quoted_string)
            
            # æ–¹æ³•2: ä¸“é—¨æŸ¥æ‰¾ NSLocalizedString("key") æ¨¡å¼
            nslocalizedstring_patterns = [
                r'NSLocalizedString\s*\(\s*"([^"]+)"\s*\)',     # NSLocalizedString("key")
                r'NSLocalizedString\s*\(\s*\'([^\']+)\'\s*\)',   # NSLocalizedString('key')
                r'NSLocalizedString\s*\(\s*@"([^"]+)"\s*\)',     # NSLocalizedString(@"key")
            ]
            
            for pattern in nslocalizedstring_patterns:
                matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
                for match in matches:
                    match = match.strip()
                    if match:
                        nslocalizedstring_keys.add(match)  # æ”¶é›†æ‰€æœ‰NSLocalizedStringä¸­çš„key
                        if match in all_defined_keys:
                            used_keys.add(match)
            
        except Exception as e:
            print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return used_keys, nslocalizedstring_keys
    
    def find_all_used_keys(self, all_defined_keys):
        """åœ¨æ•´ä¸ªé¡¹ç›®ä¸­æŸ¥æ‰¾æ‰€æœ‰ä½¿ç”¨çš„æœ¬åœ°åŒ– key"""
        # æŸ¥æ‰¾æ‰€æœ‰Swiftæ–‡ä»¶
        swift_files = self.find_swift_files()
        print(f"ğŸ“ æ‰¾åˆ° {len(swift_files)} ä¸ªSwiftæ–‡ä»¶")
        
        # æå–ä½¿ç”¨çš„key
        used_keys = set()
        all_nslocalizedstring_keys = set()  # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰NSLocalizedStringä¸­çš„key
        files_with_keys = 0
        
        for file_path in swift_files:
            file_keys, nsl_keys = self.extract_used_keys_from_file(file_path, all_defined_keys)
            if file_keys:
                files_with_keys += 1
                used_keys.update(file_keys)
            all_nslocalizedstring_keys.update(nsl_keys)
        
        print(f"ğŸ”‘ åœ¨ {files_with_keys} ä¸ªæ–‡ä»¶ä¸­æ‰¾åˆ° {len(used_keys)} ä¸ªä½¿ç”¨çš„key")
        
        # è®¡ç®—åœ¨NSLocalizedStringä¸­ä½¿ç”¨ä½†æœªåœ¨æœ¬åœ°åŒ–æ–‡ä»¶ä¸­å®šä¹‰çš„key
        missing_in_localization = all_nslocalizedstring_keys - all_defined_keys
        
        return used_keys, files_with_keys, missing_in_localization
    
    def analyze(self):
        """æ‰§è¡Œå®Œæ•´çš„æœ¬åœ°åŒ–åˆ†æ"""
        print("ğŸ” å¼€å§‹åˆ†æBarké¡¹ç›®çš„æœ¬åœ°åŒ–ä½¿ç”¨æƒ…å†µ...")
        
        # æå–æ‰€æœ‰å®šä¹‰çš„key
        print("ğŸ“– è¯»å– Localizable.xcstrings...")
        all_keys = self.extract_all_keys()
        if not all_keys:
            return None
        
        print(f"âœ… æ‰¾åˆ° {len(all_keys)} ä¸ªæœ¬åœ°åŒ–key")
        
        # æŸ¥æ‰¾ä½¿ç”¨çš„key
        used_keys, files_with_keys, missing_in_localization = self.find_all_used_keys(all_keys)
        
        # è®¡ç®—æœªä½¿ç”¨çš„key
        unused_keys = all_keys - used_keys
        missing_keys = used_keys - all_keys  # è¿™ä¸ªåº”è¯¥ä¸ºç©ºï¼Œå› ä¸ºused_keysæ˜¯ä»all_keysä¸­ç­›é€‰çš„
        
        result = {
            'total_keys': len(all_keys),
            'used_keys': len(used_keys),
            'unused_keys': len(unused_keys),
            'missing_keys': len(missing_keys),
            'missing_in_localization': len(missing_in_localization),
            'all_keys': sorted(list(all_keys)),
            'used_keys_list': sorted(list(used_keys)),
            'unused_keys_list': sorted(list(unused_keys)),
            'missing_keys_list': sorted(list(missing_keys)),
            'missing_in_localization_list': sorted(list(missing_in_localization)),
            'files_scanned': len(self.find_swift_files()),
            'files_with_keys': files_with_keys
        }
        
        return result
    
    def save_results(self, result):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        # å·²ç§»é™¤æ–‡ä»¶ä¿å­˜åŠŸèƒ½ï¼Œåªåœ¨æ§åˆ¶å°æ˜¾ç¤ºç»“æœ
        pass
    
    def print_summary(self, result):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        if not result:
            return
        
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†æç»“æœæ‘˜è¦")
        print("=" * 60)
        print(f"æ€»æœ¬åœ°åŒ–keyæ•°é‡: {result['total_keys']}")
        print(f"ä½¿ç”¨ä¸­çš„keyæ•°é‡: {result['used_keys']}")
        print(f"æœªä½¿ç”¨çš„keyæ•°é‡: {result['unused_keys']}")
        print(f"ç¼ºå¤±çš„keyæ•°é‡: {result['missing_keys']} (ä»£ç ä¸­ä½¿ç”¨ä½†æœªå®šä¹‰)")
        print(f"NSLocalizedStringä¸­ç¼ºå¤±çš„key: {result['missing_in_localization']} ä¸ª")
        
        if result['unused_keys_list']:
            print(f"\nğŸ—‘ï¸  æœªä½¿ç”¨çš„ç¿»è¯‘key ({result['unused_keys']} ä¸ª):")
            for i, key in enumerate(result['unused_keys_list'], 1):
                print(f"   {i:2d}. {key}")
        
        if result['missing_keys_list']:
            print(f"\nâš ï¸  ç¼ºå¤±çš„ç¿»è¯‘key ({result['missing_keys']} ä¸ª):")
            for i, key in enumerate(result['missing_keys_list'], 1):
                print(f"   {i:2d}. {key}")
        
        if result['missing_in_localization_list']:
            print(f"\nâŒ NSLocalizedStringä¸­ä½¿ç”¨ä½†æœªåœ¨Localizable.xcstringsä¸­å®šä¹‰çš„key ({result['missing_in_localization']} ä¸ª):")
            for i, key in enumerate(result['missing_in_localization_list'], 1):
                print(f"   {i:2d}. {key}")
        
        if not result['unused_keys_list'] and not result['missing_keys_list'] and not result['missing_in_localization_list']:
            print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰ç¿»è¯‘keyéƒ½è¢«æ­£ç¡®ä½¿ç”¨å’Œå®šä¹‰ï¼")
        
        # è®¡ç®—ä½¿ç”¨ç‡
        usage_rate = (result['used_keys'] / result['total_keys']) * 100 if result['total_keys'] > 0 else 0
        print(f"\nğŸ“ˆ ç¿»è¯‘ä½¿ç”¨ç‡: {usage_rate:.1f}%")

def main():
    project_root = "/Users/huangfeng/Documents/Bark"
    
    if not os.path.exists(project_root):
        print(f"âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_root}")
        sys.exit(1)
    
    analyzer = BarkLocalizationAnalyzer(project_root)
    
    if not analyzer.localization_file.exists():
        print(f"âŒ æœ¬åœ°åŒ–æ–‡ä»¶ä¸å­˜åœ¨: {analyzer.localization_file}")
        sys.exit(1)
    
    # æ‰§è¡Œåˆ†æ
    result = analyzer.analyze()
    
    if result:
        # æ˜¾ç¤ºç»“æœ
        analyzer.print_summary(result)
        
        print(f"\nğŸ’¡ å»ºè®®:")
        if result['unused_keys'] > 0:
            print(f"   - è€ƒè™‘åˆ é™¤ {result['unused_keys']} ä¸ªæœªä½¿ç”¨çš„ç¿»è¯‘keyä»¥å‡å°åŒ…ä½“ç§¯")
        if result['missing_keys'] > 0:
            print(f"   - ä¸º {result['missing_keys']} ä¸ªç¼ºå¤±çš„keyæ·»åŠ ç¿»è¯‘")
        if result['missing_in_localization'] > 0:
            print(f"   - ä¸º {result['missing_in_localization']} ä¸ªNSLocalizedStringä¸­çš„keyæ·»åŠ æœ¬åœ°åŒ–å®šä¹‰")
        
        print("   - æ£€æŸ¥æ˜¯å¦æœ‰åŠ¨æ€æ„å»ºçš„keyåç§°(è„šæœ¬å¯èƒ½æ— æ³•æ£€æµ‹)")
        print("   - æ‰‹åŠ¨æ£€æŸ¥Storyboard/XIBæ–‡ä»¶ä¸­çš„ç¡¬ç¼–ç å­—ç¬¦ä¸²")
    
    else:
        print("âŒ åˆ†æå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
